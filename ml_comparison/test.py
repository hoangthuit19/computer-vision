import os
import sys
import cv2
import numpy as np
from PIL import Image
import requests
from io import BytesIO


# Add parent directory to path to import our modules
sys.path.append('..')

try:
    import easyocr
    from run_easyocr import VietnameseDiacriticsEnhancer
except ImportError as e:
    print(f"Import error: {e}")
    print("Installing required packages...")
    os.system("pip install easyocr opencv-python pillow")
    import easyocr
    from run_easyocr import VietnameseDiacriticsEnhancer

def download_image_from_url(url, save_path):
    """Download image from URL and save locally"""
    try:
        response = requests.get(url)
        response.raise_for_status()
        
        # Save image
        with open(save_path, 'wb') as f:
            f.write(response.content)
        
        print(f"âœ… Image downloaded successfully: {save_path}")
        return True
    except Exception as e:
        print(f"âŒ Error downloading image: {e}")
        return False

def extract_all_text_from_image(image_path):
    """Extract all text from the provided image using enhanced Vietnamese OCR"""
    
    print("ğŸ” TRÃCH XUáº¤T TOÃ€N Bá»˜ KÃ Tá»° Tá»ª HÃŒNH áº¢NH")
    print("=" * 60)
    
    # Initialize EasyOCR with Vietnamese and English support
    print("ğŸ“š Khá»Ÿi táº¡o EasyOCR vá»›i há»— trá»£ tiáº¿ng Viá»‡t...")
    # reader = easyocr.Reader(['vi', 'en'], gpu=False)
    reader = easyocr.Reader(['vi', 'en'], gpu=False)
    
    # Initialize Vietnamese enhancer
    vietnamese_enhancer = VietnameseDiacriticsEnhancer()
    
    # Enhance image for better OCR
    print("ğŸ–¼ï¸  Cáº£i thiá»‡n cháº¥t lÆ°á»£ng hÃ¬nh áº£nh...")
    enhanced_image_path = vietnamese_enhancer.enhance_image_for_ocr(image_path)
    
    # Perform OCR
    print("ğŸ”¤ Äang thá»±c hiá»‡n OCR...")
    ocr_results = reader.readtext(enhanced_image_path)
    
    print(f"ğŸ“Š TÃ¬m tháº¥y {len(ocr_results)} vÃ¹ng text")
    print("\n" + "=" * 60)
    print("ğŸ“ TOÃ€N Bá»˜ KÃ Tá»° ÄÆ¯á»¢C TRÃCH XUáº¤T:")
    print("=" * 60)
    
    all_text_lines = []
    enhanced_text_lines = []
    
    # Sort results by vertical position (top to bottom)
    sorted_results = sorted(ocr_results, key=lambda x: min(point[1] for point in x[0]))
    
    for i, (box, text, confidence) in enumerate(sorted_results):
        # Get bounding box coordinates
        top_left = box[0]
        bottom_right = box[2]
        
        print(f"\n[{i+1:2d}] Vá»‹ trÃ­: ({int(top_left[0])}, {int(top_left[1])}) -> ({int(bottom_right[0])}, {int(bottom_right[1])})")
        print(f"     Text gá»‘c: '{text}'")
        print(f"     Äá»™ tin cáº­y: {confidence:.3f}")
        
        # Apply Vietnamese enhancement
        enhanced_text = vietnamese_enhancer.post_process_vietnamese_text(text)
        if enhanced_text != text:
            print(f"     Text cáº£i tiáº¿n: '{enhanced_text}' âœ¨")
            enhanced_text_lines.append(enhanced_text)
        else:
            enhanced_text_lines.append(text)
        
        all_text_lines.append(text)
    
    # Group text by lines (similar Y coordinates)
    def group_text_by_lines(results, threshold=30):
        """Group OCR results into lines based on Y coordinates"""
        if not results:
            return []
        
        # Create list of (avg_y, avg_x, text, enhanced_text)
        text_items = []
        for i, (box, text, confidence) in enumerate(results):
            avg_y = sum(point[1] for point in box) / 4
            avg_x = sum(point[0] for point in box) / 4
            enhanced_text = vietnamese_enhancer.post_process_vietnamese_text(text)
            text_items.append((avg_y, avg_x, text, enhanced_text))
        
        # Sort by Y coordinate
        text_items.sort(key=lambda x: x[0])
        
        # Group into lines
        lines = []
        current_line = []
        current_y = text_items[0][0] if text_items else 0
        
        for item in text_items:
            y, x, text, enhanced_text = item
            if abs(y - current_y) > threshold:
                if current_line:
                    # Sort current line by X coordinate and join
                    current_line.sort(key=lambda x: x[1])
                    line_text = ' '.join(item[2] for item in current_line)
                    enhanced_line_text = ' '.join(item[3] for item in current_line)
                    lines.append((line_text, enhanced_line_text))
                current_line = []
                current_y = y
            current_line.append(item)
        
        # Add last line
        if current_line:
            current_line.sort(key=lambda x: x[1])
            line_text = ' '.join(item[2] for item in current_line)
            enhanced_line_text = ' '.join(item[3] for item in current_line)
            lines.append((line_text, enhanced_line_text))
        
        return lines
    
    # Group text into lines
    text_lines = group_text_by_lines(ocr_results)
    
    print("\n" + "=" * 60)
    print("ğŸ“„ TEXT ÄÆ¯á»¢C NHÃ“M THEO DÃ’NG:")
    print("=" * 60)
    
    for i, (original_line, enhanced_line) in enumerate(text_lines):
        print(f"\nDÃ²ng {i+1}:")
        print(f"  Gá»‘c: '{original_line}'")
        if enhanced_line != original_line:
            print(f"  Cáº£i tiáº¿n: '{enhanced_line}' âœ¨")
    
    # Extract all unique text
    print("\n" + "=" * 60)
    print("ğŸ“‹ Táº¤T Cáº¢ KÃ Tá»° ÄÆ¯á»¢C TRÃCH XUáº¤T (KHÃ”NG TRÃ™NG Láº¶P):")
    print("=" * 60)
    
    all_unique_text = set()
    all_enhanced_text = set()
    
    for original_line, enhanced_line in text_lines:
        all_unique_text.add(original_line.strip())
        all_enhanced_text.add(enhanced_line.strip())
    
    print("\nğŸ”¤ Text gá»‘c tá»« OCR:")
    for i, text in enumerate(sorted(all_unique_text), 1):
        if text:  # Only show non-empty text
            print(f"  {i}. {text}")
    
    print("\nâœ¨ Text sau khi cáº£i tiáº¿n tiáº¿ng Viá»‡t:")
    for i, text in enumerate(sorted(all_enhanced_text), 1):
        if text:  # Only show non-empty text
            print(f"  {i}. {text}")
    
    # Analyze specific patterns
    print("\n" + "=" * 60)
    print("ğŸ” PHÃ‚N TÃCH CÃC PATTERN Äáº¶C BIá»†T:")
    print("=" * 60)
    
    combined_text = ' '.join(enhanced_text_lines).lower()
    
    # Look for time patterns
    import re
    time_patterns = re.findall(r'\d{1,2}:\d{2}', combined_text)
    if time_patterns:
        print(f"â° Thá»i gian: {time_patterns}")
    
    # Look for date patterns
    date_patterns = re.findall(r'\d{1,2}/\d{1,2}/\d{4}', combined_text)
    if date_patterns:
        print(f"ğŸ“… NgÃ y thÃ¡ng: {date_patterns}")
    
    # Look for numbers
    number_patterns = re.findall(r'\d+\.?\d*', combined_text)
    if number_patterns:
        print(f"ğŸ”¢ CÃ¡c sá»‘: {number_patterns}")
    
    # Look for Vietnamese words
    vietnamese_words = []
    for text in enhanced_text_lines:
        words = text.split()
        for word in words:
            if re.search(r'[Ã Ã¡áº£Ã£áº¡Äƒáº±áº¯áº³áºµáº·Ã¢áº§áº¥áº©áº«áº­Ã¨Ã©áº»áº½áº¹Ãªá»áº¿á»ƒá»…á»‡Ã¬Ã­á»‰Ä©á»‹Ã²Ã³á»Ãµá»Ã´á»“á»‘á»•á»—á»™Æ¡á»á»›á»Ÿá»¡á»£Ã¹Ãºá»§Å©á»¥Æ°á»«á»©á»­á»¯á»±á»³Ã½á»·á»¹á»µÄ‘]', word.lower()):
                vietnamese_words.append(word)
    
    if vietnamese_words:
        print(f"ğŸ‡»ğŸ‡³ Tá»« tiáº¿ng Viá»‡t cÃ³ dáº¥u: {list(set(vietnamese_words))}")
    
    # Clean up enhanced image
    if enhanced_image_path != image_path and os.path.exists(enhanced_image_path):
        try:
            os.remove(enhanced_image_path)
        except:
            pass
    
    print("\n" + "=" * 60)
    print("âœ… HOÃ€N THÃ€NH TRÃCH XUáº¤T TEXT!")
    print("=" * 60)
    
    return {
        'original_text_lines': [line[0] for line in text_lines],
        'enhanced_text_lines': [line[1] for line in text_lines],
        'all_text': list(all_unique_text),
        'enhanced_text': list(all_enhanced_text),
        'time_patterns': time_patterns,
        'date_patterns': date_patterns,
        'number_patterns': number_patterns,
        'vietnamese_words': list(set(vietnamese_words))
    }

def main():
    """Main function to process the provided image"""
    
    # Image URL from the user
    image_url = "/Users/thinhvp/Desktop/computer_vision/computer-vision/test_img/"
    local_image_path = "/Users/thinhvp/Desktop/computer_vision/computer-vision/test_img/test.jpg"
    
    print("ğŸ–¼ï¸  Äang táº£i hÃ¬nh áº£nh tá»« URL...")
    
    results = extract_all_text_from_image(local_image_path)
        
        # Save results to file
    with open("extracted_text_results.txt", "w", encoding="utf-8") as f:
            f.write("TOÃ€N Bá»˜ KÃ Tá»° ÄÆ¯á»¢C TRÃCH XUáº¤T Tá»ª HÃŒNH áº¢NH\n")
            f.write("=" * 60 + "\n\n")
            
            f.write("TEXT Gá»C:\n")
            for i, text in enumerate(results['all_text'], 1):
                if text.strip():
                    f.write(f"{i}. {text}\n")
            
            f.write("\nTEXT SAU KHI Cáº¢I TIáº¾N:\n")
            for i, text in enumerate(results['enhanced_text'], 1):
                if text.strip():
                    f.write(f"{i}. {text}\n")
            
            f.write(f"\nTHá»œI GIAN: {results['time_patterns']}\n")
            f.write(f"NGÃ€Y THÃNG: {results['date_patterns']}\n")
            f.write(f"CÃC Sá»: {results['number_patterns']}\n")
            f.write(f"Tá»ª TIáº¾NG VIá»†T: {results['vietnamese_words']}\n")
        
    print(f"\nğŸ’¾ Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o file: extracted_text_results.txt")
        
        # Clean up
    if os.path.exists(local_image_path):
        os.remove(local_image_path)
    
    # Download image
    # if download_image_from_url(image_url, local_image_path):
    #     # Extract text from image
        
    
    # else:
    #     print("âŒ KhÃ´ng thá»ƒ táº£i hÃ¬nh áº£nh. Vui lÃ²ng kiá»ƒm tra URL.")

if __name__ == "__main__":
    main()
